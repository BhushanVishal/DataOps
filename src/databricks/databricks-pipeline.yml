trigger:
- master

pool:
  vmImage: 'windows-latest'

stages:
  - stage: build
    jobs:
      - job:
        steps:

        - task: CopyFiles@2
          inputs:
            SourceFolder: '$(Build.SourcesDirectory)\src\databricks'
            Contents: '**'
            TargetFolder: '$(Build.ArtifactsStagingDirectory)\src'

        - task: PublishPipelineArtifact@1
          inputs:
            targetPath: '$(Build.ArtifactsStagingDirectory)'
            artifact: 'databricks'
            publishLocation: 'pipeline'
  - stage: 
    jobs:
      - job:
        steps:
        
        - task: UsePythonVersion@0
          displayName: Configuring Python Version
          inputs:
            versionSpec: '3.x'
            addToPath: true
            architecture: 'x64'

        - powershell: |
            Write-Output "[AZDO]" | Out-File ~\.databrickscfg -Encoding ASCII
            Write-Output "host = $(databricks.host)" | Out-File ~\.databrickscfg -Encoding ASCII -Append
            Write-Output "token = $(databricks.token)" | Out-File ~\.databrickscfg -Encoding ASCII -Append

            pip3 install --upgrade databricks-cli
          displayName: configuring databricks

        - powershell: |
            databricks workspace list 
            databricks workspace import_dir -o --profile AZDO $(Pipeline.Workspace)/databricks/src/ /demo
